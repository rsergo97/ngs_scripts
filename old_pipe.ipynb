{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "        --STEPS--\n",
    "1. Trimming Reads\n",
    "2. Optical duplacates deliting\n",
    "2.1. Pictures_1\n",
    "3. Genome assembling\n",
    "4. Blast to find organism\n",
    "5. Contamination erasing\n",
    "6. Reassembling\n",
    "7. Annotation\n",
    "8. Proteins\n",
    "9. Binning\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input yours raw forward and reverse reads, files extentions available - *.fastq, *.fastq.gz, *.fq\n",
    "\n",
    "raw_fastq_1 = \"/mnt/projects/dzilov/salmon14-182/reads/Salmon14-182_S4_L001_R1_001.fastq.gz\"\n",
    "raw_fastq_2 = \"/mnt/projects/dzilov/salmon14-182/reads/Salmon14-182_S4_L001_R2_001.fastq.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip -d /mnt/projects/dzilov/salmon14-182/reads/Salmon14-182_S4_L001_R1_001.fastq.gz\n",
      "gzip -d /mnt/projects/dzilov/salmon14-182/reads/Salmon14-182_S4_L001_R2_001.fastq.gz\n",
      "mv /mnt/projects/dzilov/salmon14-182/reads/Salmon14-182_S4_L001_R1_001.fastq /mnt/projects/dzilov/salmon14-182/reads/Salmon14-182_S4_L001_1.fastq\n",
      "mv /mnt/projects/dzilov/salmon14-182/reads/Salmon14-182_S4_L001_R2_001.fastq /mnt/projects/dzilov/salmon14-182/reads/Salmon14-182_S4_L001_2.fastq\n"
     ]
    }
   ],
   "source": [
    "EXECUTE_INDEX_BUILDING = False\n",
    "\n",
    "if raw_fastq_1.endswith(\".gz\"):\n",
    "    command = \"gzip -d %s\" % (raw_fastq_1)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    command = \"gzip -d %s\" % (raw_fastq_2)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    \n",
    "    raw_fastq_1 = raw_fastq_1.replace(\".gz\", \"\")\n",
    "    raw_fastq_2 = raw_fastq_2.replace(\".gz\", \"\")\n",
    "    \n",
    "if raw_fastq_1.endswith(\".tar.gz\"):\n",
    "    command = \"tar xfvz %s\" % (raw_fastq_1)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    command = \"tar xfvz %s\" % (raw_fastq_2)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    \n",
    "    raw_fastq_1 = raw_fastq_1.replace(\".tar.gz\", \"\")\n",
    "    raw_fastq_2 = raw_fastq_2.replace(\".tar.gz\", \"\")\n",
    "    \n",
    "if raw_fastq_1.endswith(\".fq\"):\n",
    "    new_raw_file_1 = raw_fastq_1.replace(\".fq\", \".fastq\")\n",
    "    command = \"mv %s %s\" % (raw_fastq_1, new_raw_file_1)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    new_raw_file_2 = raw_fastq_2.replace(\".fq\", \".fastq\")\n",
    "    command = \"mv %s %s\" % (raw_fastq_2, new_raw_file_2)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    raw_fastq_1 = new_raw_file_1\n",
    "    raw_fastq_2 = new_raw_file_2\n",
    "    \n",
    "if raw_fastq_1.endswith(\"R1_001.fastq\"):\n",
    "    new_raw_file_1 = raw_fastq_1.replace(\"R1_001.fastq\", \"1.fastq\")\n",
    "    command = \"mv %s %s\" % (raw_fastq_1, new_raw_file_1)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    new_raw_file_2 = raw_fastq_2.replace(\"R2_001.fastq\", \"2.fastq\")\n",
    "    command = \"mv %s %s\" % (raw_fastq_2, new_raw_file_2)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    raw_fastq_1 = new_raw_file_1\n",
    "    raw_fastq_2 = new_raw_file_2\n",
    "    \n",
    "if raw_fastq_1.endswith(\"_R1.fastq\"):\n",
    "    new_raw_file_1 = raw_fastq_1.replace(\"_R1.fastq\", \"_1.fastq\")\n",
    "    command = \"mv %s %s\" % (raw_fastq_1, new_raw_file_1)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    new_raw_file_2 = raw_fastq_2.replace(\"_R2.fastq\", \"_2.fastq\")\n",
    "    command = \"mv %s %s\" % (raw_fastq_2, new_raw_file_2)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    raw_fastq_1 = new_raw_file_1\n",
    "    raw_fastq_2 = new_raw_file_2\n",
    "\n",
    "assert raw_fastq_1.endswith(\"_1.fastq\")\n",
    "assert raw_fastq_2.endswith(\"_2.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salmon14-182_S4_L001\n",
      "reads\n",
      "/mnt/projects/dzilov/salmon14-182/reads\n"
     ]
    }
   ],
   "source": [
    "input1 = raw_fastq_1.split(\"/\")\n",
    "file_pref = input1[-1].split(\"_\")\n",
    "file1_pref = \"_\".join(file_pref[0:-1])\n",
    "path_to_reads = \"/\".join(input1[0:-1])\n",
    "print(file1_pref)\n",
    "reads_folder = input1[-2]\n",
    "print(reads_folder)\n",
    "print(path_to_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTINGS AND TOOLS\n",
    "# все частные штуки в сеттингсах нужно будет заменить на универсальные, для этого нужн отпарсить входные пути\\файлы\n",
    "# частные - такие как \"Ecoli19-2_S2_L001_1.fastq\", они не будут работать с другими файлами\n",
    "\n",
    "#скачать все программы с работающими на момент создания скрипта в одну папку, чтобы пайп работал только с этими версиями\n",
    "\n",
    "#составить список программ из конды и сделать аналог на снейкмейке\n",
    "\n",
    "settings = {\n",
    "    #START OPEARATIONS\n",
    "    \"trim_in_file_1\" : raw_fastq_1,\n",
    "    \"trim_in_file_2\" : raw_fastq_2,\n",
    "    \"trim_in_prefix\" : raw_fastq_1.replace(\"_1.fastq\", \"\"),\n",
    "    \"trim_out_prefix\" : raw_fastq_1.replace(\"_1.fastq\", \"\"),\n",
    "    \"trim_out_file_1\" : raw_fastq_1.replace(\"_1.fastq\", \"\") + \".trim_1.fastq\",\n",
    "    \"trim_out_file_2\" : raw_fastq_1.replace(\"_1.fastq\", \"\") + \".trim_2.fastq\",\n",
    "    \"rmdub_in_prefix\" : raw_fastq_1.replace(\"_1.fastq\", \"\") + \".trim\",\n",
    "    \"rmdub_out_prefix\" : raw_fastq_1.replace(\"_1.fastq\", \"\") + \".rm\",\n",
    "    \"rmdub_file_1\" : raw_fastq_1.replace(\"_1.fastq\", \"\") + \".rm_1.fastq\",\n",
    "    \"rmdub_file_2\" : raw_fastq_1.replace(\"_1.fastq\", \"\") + \".rm_2.fastq\",\n",
    "    \"fastqc_dir\" : path_to_reads.replace(reads_folder, \"\") + \"fastqc\",\n",
    "    \"fastqc_file\" : path_to_reads.replace(reads_folder, \"\") + \"fastqc/\" + file1_pref + \"_1_fastqc.zip\",\n",
    "    #PICTURES\n",
    "    \"jelly_dir\" : path_to_reads.replace(reads_folder, \"\") + \"jellyfish\",\n",
    "    \"jellycount_out_file\" : path_to_reads.replace(reads_folder, \"\") + \"jellyfish/\" + file1_pref + \".jf2\",\n",
    "    \"jellyhisto_out_file\" : path_to_reads.replace(reads_folder, \"\") + \"jellyfish/\" + file1_pref + \".histo\",\n",
    "    #ASSEMBLY\n",
    "    \"spades_dir\" :  path_to_reads.replace(reads_folder, \"\") + \"spades\",\n",
    "    \"spades_scaff\" : path_to_reads.replace(reads_folder, \"\") + \"spades\" + \"/scaffolds.fasta\",\n",
    "    \"spades_cont\" : path_to_reads.replace(reads_folder, \"\") + \"spades\" + \"/contigs.fasta\",\n",
    "    \"uni_dir\" : path_to_reads.replace(reads_folder, \"\") + \"unicycler\",\n",
    "    \"uni_out\" : path_to_reads.replace(reads_folder, \"\") + \"unicycler\" + \"/assembly.fasta\",\n",
    "    # BLAST\n",
    "    \"blast_dir\" : path_to_reads.replace(reads_folder, \"\") + \"blast\",\n",
    "    \"blast_db\" : \"/mnt/projects/shared/ncbi/blast/db/nt\", #ШО ДЕЛАТЬ С ЭТИМ???\n",
    "    \"blastn_out\" : path_to_reads.replace(reads_folder, \"\") + \"blast\" + \"/\" + file1_pref +\".outfmt6\",\n",
    "    # FILTERING\n",
    "    \"filter_out\" : path_to_reads.replace(reads_folder, \"\") + \"blast\" + \"/\" + file1_pref + \".best_single_hits.blastn\",\n",
    "    \"index_file\" : path_to_reads.replace(reads_folder, \"\") + \"spades\" + \"/scaffolds.fasta.fai\",\n",
    "    \"scaffolds_filtered\" : path_to_reads.replace(reads_folder, \"\") + \"spades\" + \"/scaffolds_filtered.fasta\",\n",
    "    \"quast_dir\" : path_to_reads.replace(reads_folder, \"\") + \"quast\",\n",
    "    \"quast_out\" : path_to_reads.replace(reads_folder, \"\") + \"quast/\" + \"report.txt\",\n",
    "    # ANNOTATION\n",
    "    \"prokka_dir\" : path_to_reads.replace(reads_folder, \"\") + \"prokka\",\n",
    "    # PROTEINS    \n",
    "    \"eggnog_path\" : \"/mnt/projects/vdikaya/Tools/eggnog-mapper-1.0.3/emapper.py\", #при создании скрипта поменять на путь к файлу\n",
    "    \"eggnog_dir\" : path_to_reads.replace(reads_folder, \"\") + \"eggnog/\",\n",
    "    \"eggnog_ann\" : path_to_reads.replace(reads_folder, \"\") + \"eggnog/\" + \"eggnog.emapper.annotations\",\n",
    "}\n",
    "\n",
    "tools = {\n",
    "    # START OPERATIONS\n",
    "    \"v2trim\" : \"/mnt/projects/shared/tools/V2_trim.exe %(trim_in_prefix)s %(trim_out_prefix)s 20 0 fastq /mnt/projects/shared/tools/illumina_ext.data\",\n",
    "    \"rmdub\" : \"/mnt/projects/shared/tools/rmdup.exe %(rmdub_in_prefix)s %(rmdub_out_prefix)s 3000 3 0,30\",\n",
    "    # PICTURES\n",
    "    \"fastqc\" : \"fastqc -o %(fastqc_dir)s -t 32 %(trim_in_file_1)s %(trim_in_file_2)s\",\n",
    "    \"jellycount\" : \"jellyfish count -m 23 -t 30 -s 2G -C -o %(jellycount_out_file)s %(trim_out_file_1)s %(trim_out_file_2)s\",\n",
    "    \"jellyhisto\" : \"jellyfish histo -o %(jellyhisto_out_file)s %(jellycount_out_file)s\",\n",
    "    # ASSEMBLY\n",
    "    \"spades\" : \"spades -t 32 -1 %(rmdub_file_1)s -2 %(rmdub_file_2)s -o %(spades_dir)s\",\n",
    "    \"unicycler\" : \"unicycler -1 %(rmdub_file_1)s -2 %(rmdub_file_2)s -o %(uni_dir)s -t 32 --mode normal\",\n",
    "    # BLAST\n",
    "    \"blastn\" : \"blastn -query %(spades_scaff)s -db %(blast_db)s -max_target_seqs 5 -outfmt 6 -evalue 1e-5 -num_threads 32 -out %(blastn_out)s\",\n",
    "    # FILTERING\n",
    "    \"filter\" : \"less %(blastn_out)s | sort  -k1,1 -k12,12nr -k11,11n | sort -u -k1,1 --merge > %(filter_out)s\",\n",
    "    \"index\" : \"samtools faidx %(spades_scaff)s\", \n",
    "    \"quast\" : \"/mnt/projects/dzilov/soft/quast/quast-5.0.2/quast.py -o %(quast_dir)s %(scaffolds_filtered)s\",\n",
    "    # ANNOTATION\n",
    "    \"prokka\" : \"prokka --cpus 32 --outdir %(prokka_dir)s %(scaffolds_filtered)s\",\n",
    "    # PROTEINS\n",
    "    \"blastp\" : \"\"\"\n",
    "    time blastp -db /mnt/projects/shared/ncbi/STRING/protein.sequences.v11.0.fa -query PROKKA_02052020.faa \n",
    "    -out PROKKA_02052020.string.blast -max_target_seqs 5 -outfmt \"6 qseqid qgi qacc qaccver qlen sseqid sallseqid\n",
    "    sgi sallgi sacc saccver sallacc slen qstart qend sstart send qseq sseq evalue bitscore score length pident nident\n",
    "    mismatch positive gapopen gaps ppos frames qframe sframe btop staxids sscinames scomnames sblastnames\n",
    "    sskingdoms stitle salltitles sstrand qcovs qcovhsp\" -evalue 1e-5 -num_threads 32\n",
    "    \"\"\",\n",
    "    \"eggnog\" : \"python2 %(eggnog_path)s -i %(prokka_faa)s --output %(eggnog_dir)s -m diamond --cpu 32 --report_orthologs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done Trimming\n"
     ]
    }
   ],
   "source": [
    "# TESTED, WORKS\n",
    "#1 STEP TRIMMING\n",
    "\n",
    "command = tools[\"v2trim\"] % settings\n",
    "check_file = os.path.exists(settings[\"trim_out_file_1\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"trim_out_file_1\"]) > 0:\n",
    "        print(\"U've already done Trimming\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done RMDUB\n"
     ]
    }
   ],
   "source": [
    "# TESTED, WORKS\n",
    "#2 STEP Optical duplacates deliting\n",
    "\n",
    "assert os.path.exists(settings[\"trim_out_file_1\"])\n",
    "assert os.path.getsize(settings[\"trim_out_file_1\"]) > 0\n",
    "\n",
    "command = tools[\"rmdub\"] % settings\n",
    "check_file = os.path.exists(settings[\"rmdub_file_1\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"rmdub_file_1\"]) > 0:\n",
    "        print(\"U've already done RMDUB\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done FASTQC\n"
     ]
    }
   ],
   "source": [
    "# TESTED, WORKS\n",
    "#2.1. STEP PICTURES_1\n",
    "#2.1.1. FASTQC OF RAW READS\n",
    "assert os.path.exists(settings[\"trim_in_file_1\"])\n",
    "assert os.path.getsize(settings[\"trim_in_file_1\"]) > 0\n",
    "\n",
    "# CREATING DIRECTORIES\n",
    "\n",
    "if os.path.exists(settings[\"fastqc_dir\"]) == False:\n",
    "    os.mkdir(settings[\"fastqc_dir\"])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# FASTQCSHING\n",
    "\n",
    "command = tools[\"fastqc\"] % settings\n",
    "check_file = os.path.exists(settings[\"fastqc_file\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"fastqc_file\"]) > 0:\n",
    "        print(\"U've already done FASTQC\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done JellyCount\n"
     ]
    }
   ],
   "source": [
    "# TESTED, WORKS\n",
    "#2.1.2. JELLYFISH OF TRIMMED READS\n",
    "assert os.path.exists(settings[\"trim_out_file_1\"])\n",
    "assert os.path.getsize(settings[\"trim_out_file_1\"]) > 0\n",
    "\n",
    "# CREATING DIRECTORIES\n",
    "\n",
    "if os.path.exists(settings[\"jelly_dir\"]) == False:\n",
    "    os.mkdir(settings[\"jelly_dir\"])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# JELLYFISHING\n",
    "\n",
    "command = tools[\"jellycount\"] % settings\n",
    "check_file = os.path.exists(settings[\"jellycount_out_file\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"jellycount_out_file\"]) > 0:\n",
    "        print(\"U've already done JellyCount\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done JellyHysto\n"
     ]
    }
   ],
   "source": [
    "# TESTED, WORKS\n",
    "#2.1.3 JELLYFISH HISTOGRAM\n",
    "assert os.path.exists(settings[\"jellycount_out_file\"])\n",
    "assert os.path.getsize(settings[\"jellycount_out_file\"]) > 0\n",
    "\n",
    "command = tools[\"jellyhisto\"] % settings\n",
    "check_file = os.path.exists(settings[\"jellyhisto_out_file\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"jellyhisto_out_file\"]) > 0:\n",
    "        print(\"U've already done JellyHysto\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done Spades\n"
     ]
    }
   ],
   "source": [
    "# TESTED, WORKS\n",
    "#3 STEP GENOME ASSEMBLING (когда буду писать программу нужно задать в аргументах метод сборки, от него потом зависит бласт,\n",
    "# по дефолту спадес)\n",
    "#3.1. SPADES\n",
    "assert os.path.exists(settings[\"rmdub_out_prefix\"] + \"_1.fastq\")\n",
    "assert os.path.getsize(settings[\"rmdub_out_prefix\"] + \"_1.fastq\") > 0\n",
    "\n",
    "# CREATING DIRECTORIES\n",
    "\n",
    "if os.path.exists(settings[\"spades_dir\"]) == False:\n",
    "    os.mkdir(settings[\"spades_dir\"])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# SPADISHING\n",
    "\n",
    "command = tools[\"spades\"] % settings\n",
    "check_file = os.path.exists(settings[\"spades_scaff\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"spades_scaff\"]) > 0:\n",
    "        print(\"U've already done Spades\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done Unicycler\n"
     ]
    }
   ],
   "source": [
    "# TESTED, WORKS\n",
    "#3.2. UNICYCLER\n",
    "# conda install unicycler\n",
    "# conda update --prefix /home/dzilov/soft/miniconda3 unicycler\n",
    "\n",
    "assert os.path.exists(settings[\"rmdub_out_prefix\"] + \"_1.fastq\")\n",
    "assert os.path.getsize(settings[\"rmdub_out_prefix\"] + \"_1.fastq\") > 0\n",
    "\n",
    "# CREATING DIRECTORIES\n",
    "\n",
    "if os.path.exists(settings[\"uni_dir\"]) == False:\n",
    "    os.mkdir(settings[\"uni_dir\"])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# UNICYCLISHING\n",
    "\n",
    "command = tools[\"unicycler\"] % settings\n",
    "check_file = os.path.exists(settings[\"uni_out\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"uni_out\"]) > 0:\n",
    "        print(\"U've already done Unicycler\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done Blastn\n"
     ]
    }
   ],
   "source": [
    "# TESTED, WORKS\n",
    "# 4 STEP BLAST\n",
    "\n",
    "assert os.path.exists(settings[\"spades_scaff\"])\n",
    "assert os.path.getsize(settings[\"spades_scaff\"]) > 0\n",
    "\n",
    "# CREATING DIRECTORIES\n",
    "\n",
    "if os.path.exists(settings[\"blast_dir\"]) == False:\n",
    "    os.mkdir(settings[\"blast_dir\"])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if os.path.exists(settings[\"blastn_out\"]) == False:\n",
    "    os.mknod(settings[\"blastn_out\"])\n",
    "else:\n",
    "    pass\n",
    "# BLASTISHING\n",
    "\n",
    "command = tools[\"blastn\"] % settings\n",
    "check_file = os.path.exists(settings[\"blastn_out\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"blastn_out\"]) > 0:\n",
    "        print(\"U've already done Blastn\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done Filtering\n"
     ]
    }
   ],
   "source": [
    "# TESTED, WORKS\n",
    "# 5 STEP FILTERING\n",
    "\n",
    "assert os.path.exists(settings[\"blastn_out\"])\n",
    "assert os.path.getsize(settings[\"blastn_out\"]) > 0\n",
    "\n",
    "command = tools[\"filter\"] % settings\n",
    "check_file = os.path.exists(settings[\"filter_out\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"filter_out\"]) > 0:\n",
    "        print(\"U've already done Filtering\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done Indexing\n"
     ]
    }
   ],
   "source": [
    "# FASTA INDEXING\n",
    "\n",
    "assert os.path.exists(settings[\"spades_scaff\"])\n",
    "assert os.path.getsize(settings[\"spades_scaff\"]) > 0\n",
    "\n",
    "command = tools[\"index\"] % settings\n",
    "check_file = os.path.exists(settings[\"index_file\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"index_file\"]) > 0:\n",
    "        print(\"U've already done Indexing\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "ncbi = myclient[\"NCBI\"]\n",
    "refids = ncbi.refids\n",
    "taxids = ncbi.taxids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6 CONTAMINATION ERASING\n",
    "\n",
    "assert os.path.exists(settings[\"index_file\"])\n",
    "assert os.path.getsize(settings[\"index_file\"]) > 0\n",
    "        \n",
    "bact_fai = settings[\"index_file\"]\n",
    "cont_to_len = {}\n",
    "with open(bact_fai) as fh:\n",
    "    for line in fh:\n",
    "        a = line.strip().split(\"\\t\")\n",
    "        cont_to_len[a[0]] = int(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(settings[\"filter_out\"])\n",
    "assert os.path.getsize(settings[\"filter_out\"]) > 0\n",
    "\n",
    "blast_file = settings[\"filter_out\"]\n",
    "cont_to_blast = {}\n",
    "with open(blast_file) as fh:\n",
    "    for line in fh:\n",
    "        a = line.strip().split(\"\\t\")\n",
    "        cont_to_blast[a[0]] = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "count_names = Counter()\n",
    "count_id = Counter()\n",
    "total_length = 0\n",
    "not_bacteria_node = []\n",
    "for key, value in cont_to_blast.items():\n",
    "    length = cont_to_len[key]\n",
    "    val_split = value.split('.')[0]\n",
    "    taxon_id = refids.find_one({\"accession\":val_split})[\"taxid\"]\n",
    "    taxon_name = taxids.find_one({\"_id\":taxon_id})[\"name\"]\n",
    "    taxon_name = \" \".join(taxon_name.split()[:2])\n",
    "    count_names[taxon_name] += length\n",
    "    count_id[taxon_id] += length\n",
    "    total_length += length\n",
    "    if taxon_name != count_names.most_common()[0][0]:\n",
    "        not_bacteria_node.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salmonella enterica 97.04%\n",
      "Escherichia coli 2.53%\n",
      "Klebsiella pneumoniae 0.4%\n",
      "Bacillus cereus 0.02%\n",
      "Cutibacterium acnes 0.01%\n",
      "Psychrobacillus sp. 0.01%\n"
     ]
    }
   ],
   "source": [
    "for taxon, size in count_names.most_common(100):\n",
    "    print(taxon, \"%s%%\" % round(100.*size/total_length, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MOST COMMON ID IS : 550537\n"
     ]
    }
   ],
   "source": [
    "bacteria_id = count_id.most_common()[0][0]\n",
    "print(\"THE MOST COMMON ID IS :\", bacteria_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NODES TO BE ERASED: ['NODE_14_length_87187_cov_177.727452', 'NODE_18_length_34700_cov_347.014954', 'NODE_22_length_18653_cov_345.649628', 'NODE_33_length_665_cov_827.111524', 'NODE_36_length_487_cov_0.833333', 'NODE_38_length_475_cov_0.882184', 'NODE_40_length_459_cov_0.641566', 'NODE_41_length_455_cov_0.692073', 'NODE_43_length_430_cov_0.755776', 'NODE_54_length_128_cov_352.000000']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(\"NODES TO BE ERASED:\", not_bacteria_node)\n",
    "print(len(not_bacteria_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = {}\n",
    "header = None\n",
    "with open(settings[\"spades_scaff\"]) as fh:\n",
    "    for i, line in enumerate(fh):\n",
    "        line = line.strip()\n",
    "        if line.startswith(\">\"):\n",
    "            if header:\n",
    "                fasta[header]=\"\".join(seq)\n",
    "            header = line\n",
    "            seq = []\n",
    "        else:\n",
    "            seq.append(line)\n",
    "if header:\n",
    "    fasta[header] = \"\".join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(not_bacteria_node) - 1:\n",
    "    if \">\" + not_bacteria_node[i] in fasta.keys():\n",
    "            fasta.pop(\">\" + not_bacteria_node[i])\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(settings[\"scaffolds_filtered\"], \"w\")\n",
    "for key, value in fasta.items():\n",
    "    f.write(key + \"\\n\" + value + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done QUAST\n"
     ]
    }
   ],
   "source": [
    "# Analize of assembly\n",
    "# TESTED, WORKS\n",
    "assert os.path.exists(settings[\"scaffolds_filtered\"])\n",
    "assert os.path.getsize(settings[\"scaffolds_filtered\"]) > 0\n",
    "\n",
    "# CREATING DIRECTORIES\n",
    "\n",
    "if os.path.exists(settings[\"quast_dir\"]) == False:\n",
    "    os.mkdir(settings[\"quast_dir\"])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# QUASTING\n",
    "\n",
    "command = tools[\"quast\"] % settings\n",
    "check_file = os.path.exists(settings[\"quast_out\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"quast_out\"]) > 0:\n",
    "        print(\"U've already done QUAST\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done PROKKA\n"
     ]
    }
   ],
   "source": [
    "# Analize of assembly\n",
    "# TESTED, WORKS\n",
    "assert os.path.exists(settings[\"scaffolds_filtered\"])\n",
    "assert os.path.getsize(settings[\"scaffolds_filtered\"]) > 0\n",
    "\n",
    "# PROKKING\n",
    "\n",
    "command = tools[\"prokka\"] % settings\n",
    "check_file = os.path.exists(settings[\"prokka_dir\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"prokka_dir\"]) > 0:\n",
    "        print(\"U've already done PROKKA\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings[\"prokka_faa\"] = settings[\"prokka_dir\"] + \"/\" + os.listdir(settings[\"prokka_dir\"])[0].split(\".\")[0] + \".faa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U've already done EGGNOG\n"
     ]
    }
   ],
   "source": [
    "# Analize of assembly\n",
    "# TESTED, WORKS\n",
    "assert os.path.exists(settings[\"prokka_faa\"])\n",
    "assert os.path.getsize(settings[\"prokka_faa\"]) > 0\n",
    "\n",
    "# CREATING DIRECTORIES\n",
    "\n",
    "if os.path.exists(settings[\"eggnog_dir\"]) == False:\n",
    "    os.mkdir(settings[\"eggnog_dir\"])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# EMAPPING\n",
    "\n",
    "command = tools[\"eggnog\"] % settings\n",
    "check_file = os.path.exists(settings[\"eggnog_ann\"])\n",
    "if check_file == True:\n",
    "    if os.path.getsize(settings[\"eggnog_ann\"]) > 0:\n",
    "        print(\"U've already done EGGNOG\")\n",
    "        pass\n",
    "    else:\n",
    "        print(command)\n",
    "        #os.system(command)\n",
    "else:\n",
    "    print(command)\n",
    "    #os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "obo_annotation = \"/mnt/projects/shared/go.obo\"\n",
    "settings[\"anno_file\"] = settings[\"eggnog_ann\"] + \".tsv\"\n",
    "settings[\"gene_copy_file\"] = settings[\"eggnog_ann\"] + \".gene_copy.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_GO = {}\n",
    "header = None\n",
    "with open (obo_annotation) as fh:\n",
    "    for line in fh:\n",
    "        line = line.strip()\n",
    "        if line.startswith('id: GO') and header == None:\n",
    "            header = line.replace('id: ', '')\n",
    "            seq = []\n",
    "            continue\n",
    "        elif line.startswith('id: GO') and header != None:\n",
    "            dict_GO[header] = \" \".join(seq[:-2]).lower()\n",
    "            header = line.replace('id: ', '')\n",
    "            seq = []\n",
    "        elif line.startswith(\"[Typedef]\"):\n",
    "            dict_GO[header] = \" \".join(seq[:-2]).lower()\n",
    "            break\n",
    "        elif header != None:\n",
    "            seq.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_of_interest = set()\n",
    "with open(settings[\"eggnog_ann\"]) as fh:\n",
    "    for line in fh:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        line = line.strip().split('\\t')\n",
    "        gene_name = line[4]\n",
    "        GO = line[5].split(',')\n",
    "        for go in GO:\n",
    "            if go in dict_GO and 'antigen'in dict_GO[go] and 'length' in dict_GO[go]:\n",
    "                #print(go, gene_name, dict_GO[go])\n",
    "                #break\n",
    "                gene_of_interest.add(gene_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gene_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(gene_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "go2genes = defaultdict(list)\n",
    "with open(settings[\"anno_file\"], \"w\") as fa:\n",
    "    with open(settings[\"eggnog_ann\"]) as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            line = line.strip().split(\"\\t\")  \n",
    "            gene_name = line[4]\n",
    "            GO = line[5].split(\",\")\n",
    "            for go in GO:\n",
    "                if go in dict_GO:\n",
    "                    \n",
    "                    if not line[4]:\n",
    "                        line[4] = \"NA\"\n",
    "                    gene_name = \"%s:%s\" % (line[0], line[4])\n",
    "                    go2genes[go].append(gene_name)\n",
    "    for go in go2genes.keys():\n",
    "        fa.write(\"%s\\t%s\\t%s\\n\" % (go, \",\".join(list(set(go2genes[go]))), dict_GO[go]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_copy = defaultdict(int)\n",
    "with open(settings[\"eggnog_ann\"]) as fh:\n",
    "    for line in fh:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        line = line.strip().split(\"\\t\")  \n",
    "        if not line[4]:\n",
    "            line[4] = \"NA\"\n",
    "        else:\n",
    "            gene_copy[line[4]] += 1\n",
    "\n",
    "\n",
    "with open(settings[\"gene_copy_file\"], \"w\") as fw:\n",
    "    for gene_name, copy_number in gene_copy.items():\n",
    "        fw.write(\"%s\\t%s\\n\" % (gene_name, copy_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
